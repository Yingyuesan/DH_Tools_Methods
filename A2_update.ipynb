{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /Users/oyuesan/opt/anaconda3/lib/python3.9/site-packages (from -r requirement.txt (line 1)) (4.1.2)\n",
      "Requirement already satisfied: numpy in /Users/oyuesan/opt/anaconda3/lib/python3.9/site-packages (from -r requirement.txt (line 2)) (1.22.4)\n",
      "Requirement already satisfied: pandas in /Users/oyuesan/opt/anaconda3/lib/python3.9/site-packages (from -r requirement.txt (line 3)) (1.4.2)\n",
      "Requirement already satisfied: pyLDAvis in /Users/oyuesan/opt/anaconda3/lib/python3.9/site-packages (from -r requirement.txt (line 4)) (3.4.0)\n",
      "Requirement already satisfied: nltk in /Users/oyuesan/opt/anaconda3/lib/python3.9/site-packages (from -r requirement.txt (line 5)) (3.7)\n",
      "Requirement already satisfied: scikit-learn in /Users/oyuesan/opt/anaconda3/lib/python3.9/site-packages (from -r requirement.txt (line 6)) (1.2.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/oyuesan/opt/anaconda3/lib/python3.9/site-packages (from gensim->-r requirement.txt (line 1)) (5.1.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /Users/oyuesan/opt/anaconda3/lib/python3.9/site-packages (from gensim->-r requirement.txt (line 1)) (1.7.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/oyuesan/opt/anaconda3/lib/python3.9/site-packages (from pandas->-r requirement.txt (line 3)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/oyuesan/opt/anaconda3/lib/python3.9/site-packages (from pandas->-r requirement.txt (line 3)) (2021.3)\n",
      "Requirement already satisfied: jinja2 in /Users/oyuesan/opt/anaconda3/lib/python3.9/site-packages (from pyLDAvis->-r requirement.txt (line 4)) (2.11.3)\n",
      "Requirement already satisfied: funcy in /Users/oyuesan/opt/anaconda3/lib/python3.9/site-packages (from pyLDAvis->-r requirement.txt (line 4)) (1.18)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/oyuesan/opt/anaconda3/lib/python3.9/site-packages (from pyLDAvis->-r requirement.txt (line 4)) (1.2.0)\n",
      "Requirement already satisfied: numexpr in /Users/oyuesan/opt/anaconda3/lib/python3.9/site-packages (from pyLDAvis->-r requirement.txt (line 4)) (2.8.1)\n",
      "Requirement already satisfied: setuptools in /Users/oyuesan/opt/anaconda3/lib/python3.9/site-packages (from pyLDAvis->-r requirement.txt (line 4)) (61.2.0)\n",
      "Requirement already satisfied: click in /Users/oyuesan/opt/anaconda3/lib/python3.9/site-packages (from nltk->-r requirement.txt (line 5)) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/oyuesan/opt/anaconda3/lib/python3.9/site-packages (from nltk->-r requirement.txt (line 5)) (2022.3.15)\n",
      "Requirement already satisfied: tqdm in /Users/oyuesan/opt/anaconda3/lib/python3.9/site-packages (from nltk->-r requirement.txt (line 5)) (4.64.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/oyuesan/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->-r requirement.txt (line 6)) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/oyuesan/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->-r requirement.txt (line 3)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/oyuesan/opt/anaconda3/lib/python3.9/site-packages (from jinja2->pyLDAvis->-r requirement.txt (line 4)) (2.0.1)\n",
      "Requirement already satisfied: packaging in /Users/oyuesan/opt/anaconda3/lib/python3.9/site-packages (from numexpr->pyLDAvis->-r requirement.txt (line 4)) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/oyuesan/opt/anaconda3/lib/python3.9/site-packages (from packaging->numexpr->pyLDAvis->-r requirement.txt (line 4)) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirement.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/oyuesan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/oyuesan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/oyuesan/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim import corpora, models\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk import WordNetLemmatizer\n",
    "import gensim\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim import corpora\n",
    "import pyLDAvis.gensim_models\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from the file 'DH_CollectingData2022_review.tsv.txt'\n",
    "df = pd.read_csv('DH_CollectingData2022_review.tsv', sep='\\t', header=None, names=['sentence', 'sentiment'],\n",
    "                 encoding='utf-8')\n",
    "# Create a set of stop words in English\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# Create a WordNetLemmatizer object to perform lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "# Preprocess function\n",
    "def preprocess(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "    # Tokenize text using simple_preprocess\n",
    "    tokens = simple_preprocess(text, deacc=True)\n",
    "    # Remove stopwords\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    # Lemmatize words\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    # Join tokens back into string\n",
    "    return tokens\n",
    "\n",
    "# Define a function named get_num that takes a row of data as input\n",
    "def get_num(row):\n",
    "    # Extract the sentence and sentiment values from the row\n",
    "    sentence = row['sentence']\n",
    "    number = row['sentiment']\n",
    "    # If the sentiment value is not NaN, return it\n",
    "    if pd.notna(row['sentiment']):\n",
    "        return number\n",
    "    # The bug fix for file.\n",
    "    if sentence and sentence[-1].isdigit():\n",
    "        # If the last character of the sentence is a digit, extract the number.\n",
    "        if len(sentence) > 1 and sentence[-2] == '-':\n",
    "            return int(sentence[-1])\n",
    "        # Otherwise, the number is positive\n",
    "        else:\n",
    "            return -int(sentence[-1])\n",
    "    # If the sentence doesn't end with a digit, return NaN\n",
    "    else:\n",
    "        return pd.NA\n",
    "\n",
    "# Apply get_num to 'sentiment' column\n",
    "df['sentiment'] = df.apply(get_num, axis=1)\n",
    "# Apply preprocessing to 'sentence' column\n",
    "df['clean_text'] = df['sentence'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>For Nik, he only wants to silence the cacophon...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[nik, want, silence, cacophony, sound, color, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I can play this two ways\\t0</td>\n",
       "      <td>0</td>\n",
       "      <td>[play, two, way]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mild, because it isn't conclusive, and doesn't...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>[mild, isnt, conclusive, doesnt, give, u, info...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You can also get some more information about t...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[also, get, information, book, writing, exclus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Soon, Hero, who has never had friends, is thru...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[soon, hero, never, friend, thrust, school, qu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence sentiment  \\\n",
       "0  For Nik, he only wants to silence the cacophon...       0.0   \n",
       "1                        I can play this two ways\\t0         0   \n",
       "2  Mild, because it isn't conclusive, and doesn't...      -1.0   \n",
       "3  You can also get some more information about t...       0.0   \n",
       "4  Soon, Hero, who has never had friends, is thru...       0.0   \n",
       "\n",
       "                                          clean_text  \n",
       "0  [nik, want, silence, cacophony, sound, color, ...  \n",
       "1                                   [play, two, way]  \n",
       "2  [mild, isnt, conclusive, doesnt, give, u, info...  \n",
       "3  [also, get, information, book, writing, exclus...  \n",
       "4  [soon, hero, never, friend, thrust, school, qu...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 keywords:  ['way', 'little', 'mystery', 'did', 'interesting', 'world', 'reading', 'think', 'character', 'great', 'novel', 'love', 'really', 'like', 'good', 'characters', 'just', 'story', 'read', 'book']\n"
     ]
    }
   ],
   "source": [
    "# Get all sentences from the 'clean_text' column of the DataFrame and create a list\n",
    "all_sentences = df['clean_text'].tolist()\n",
    "# Create a TF-IDF matrix using the TfidfVectorizer from scikit-learn\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=20)\n",
    "tfidf_matrix = vectorizer.fit_transform(df['sentence'])\n",
    "# Extract the top 20 keywords from the TF-IDF matrix\n",
    "# First, sort the feature weights in descending order\n",
    "indices = np.argsort(vectorizer.idf_)[::-1]\n",
    "# Get the feature names from the vectorizer\n",
    "features = vectorizer.get_feature_names_out()\n",
    "# Set the number of top features to extract\n",
    "top_n = 20\n",
    "# Create a list of the top n features\n",
    "top_features = [features[i] for i in indices[:top_n]]\n",
    "# Print the top features\n",
    "print(\"Top 20 keywords: \", top_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame containing only the rows where the 'sentiment' column equals 1 (positive sentiment)\n",
    "positive_df = df[df['sentiment'] == 1]\n",
    "# Create a new DataFrame containing only the rows where the 'sentiment' column equals -1 (negative sentiment)\n",
    "negative_df = df[df['sentiment'] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the 'clean_text' column from the positive and negative DataFrames\n",
    "data_words_pos = positive_df['clean_text']\n",
    "data_words_neg = negative_df['clean_text']\n",
    "# Define the range of hyperparameters to test\n",
    "num_topics_range = [3, 5, 7]\n",
    "num_passes_range = [5, 10, 15]\n",
    "chunksize_range = [3, 5, 7, 9]\n",
    "# Define a function to calculate the coherence score for a given model\n",
    "def compute_coherence(model, corpus, texts):\n",
    "    coherence_model = CoherenceModel(model=model, corpus=corpus, texts=texts, coherence='c_v')\n",
    "    return coherence_model.get_coherence()\n",
    "# Initialize variables to store the best hyperparameters and resulting model\n",
    "def find_best_hyperparameter(texts):\n",
    "    best_coherence = 0\n",
    "    best_num_topics = None\n",
    "    best_num_passes = None\n",
    "    best_chunksize = None\n",
    "    best_model = None\n",
    "    dictionary = corpora.Dictionary(texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "    # Perform grid search\n",
    "    for i, num_topics in enumerate(num_topics_range):\n",
    "        for j, num_passes in enumerate(num_passes_range):\n",
    "            for k, chunksize in enumerate(chunksize_range):\n",
    "                # Fit the LDA model using the current hyperparameters\n",
    "                lda_model = gensim.models.ldamodel.LdaModel(\n",
    "                    corpus=corpus, id2word=dictionary, num_topics=num_topics,\n",
    "                    random_state=42, update_every=1, chunksize=chunksize,\n",
    "                    passes=num_passes, alpha='auto', per_word_topics=True\n",
    "                )\n",
    "                # Compute coherence score for the resulting model\n",
    "                coherence = compute_coherence(lda_model, corpus, texts)\n",
    "                # Update the best hyperparameters and resulting model if coherence score is higher\n",
    "                if coherence > best_coherence:\n",
    "                    best_coherence = coherence\n",
    "                    best_num_topics = num_topics\n",
    "                    best_num_passes = num_passes\n",
    "                    best_chunksize = chunksize\n",
    "                    best_model = lda_model\n",
    "    return best_coherence, best_num_topics, best_num_passes, best_chunksize, best_model, corpus, dictionary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best coherence: 0.6117331561233724\n",
      "Best num topics: 5\n",
      "Best num passes: 15\n",
      "Best chunksize: 3\n",
      "[(0, '0.066*\"read\" + 0.021*\"voice\" + 0.016*\"see\" + 0.015*\"mystery\" + 0.015*\"fun\" + 0.015*\"liked\" + 0.011*\"great\" + 0.011*\"kept\" + 0.010*\"also\" + 0.010*\"story\"'), (1, '0.022*\"bit\" + 0.021*\"im\" + 0.021*\"new\" + 0.020*\"hill\" + 0.019*\"really\" + 0.018*\"take\" + 0.017*\"thriller\" + 0.014*\"little\" + 0.014*\"coming\" + 0.012*\"perfect\"'), (2, '0.048*\"character\" + 0.025*\"much\" + 0.022*\"took\" + 0.021*\"lot\" + 0.018*\"reader\" + 0.015*\"better\" + 0.014*\"think\" + 0.012*\"way\" + 0.010*\"get\" + 0.010*\"part\"'), (3, '0.068*\"book\" + 0.056*\"well\" + 0.023*\"interesting\" + 0.020*\"time\" + 0.013*\"crawford\" + 0.011*\"something\" + 0.010*\"worth\" + 0.010*\"evil\" + 0.008*\"he\" + 0.008*\"tale\"'), (4, '0.027*\"good\" + 0.024*\"novel\" + 0.023*\"star\" + 0.021*\"writer\" + 0.012*\"beautiful\" + 0.012*\"enjoy\" + 0.010*\"first\" + 0.009*\"life\" + 0.008*\"every\" + 0.008*\"make\"')]\n"
     ]
    }
   ],
   "source": [
    "# Print the best hyperparameters and resulting model\n",
    "best_coherence, best_num_topics, best_num_passes, best_chunksize, best_model, corpus, dictionary = find_best_hyperparameter(data_words_pos)\n",
    "# Print the best hyperparameters and coherence score\n",
    "print('Best coherence:', best_coherence)\n",
    "print('Best num topics:', best_num_topics)\n",
    "print('Best num passes:', best_num_passes)\n",
    "print('Best chunksize:', best_chunksize)\n",
    "# Print the top topics and their associated keywords for the resulting model\n",
    "print(best_model.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oyuesan/opt/anaconda3/lib/python3.9/site-packages/pyLDAvis/_prepare.py:243: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  default_term_info = default_term_info.sort_values(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el321751403262719728486253701071\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el321751403262719728486253701071_data = {\"mdsDat\": {\"x\": [-0.03764044409586376, -0.02525907216365096, 0.10034952987292586, -0.024585357806322258, -0.012864655807088822], \"y\": [-0.07451918434803827, 0.06299363562180589, -0.007663756789315766, 0.016880917457831136, 0.002308388057716997], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [23.03489041141313, 21.179990283510094, 20.02046257789151, 18.27138574980907, 17.493270977376195]}, \"tinfo\": {\"Term\": [\"read\", \"book\", \"well\", \"character\", \"good\", \"much\", \"novel\", \"bit\", \"took\", \"star\", \"lot\", \"voice\", \"writer\", \"im\", \"time\", \"new\", \"hill\", \"interesting\", \"really\", \"reader\", \"take\", \"see\", \"mystery\", \"fun\", \"liked\", \"thriller\", \"think\", \"little\", \"way\", \"coming\", \"read\", \"voice\", \"fun\", \"mystery\", \"liked\", \"see\", \"great\", \"story\", \"two\", \"many\", \"magic\", \"also\", \"kept\", \"would\", \"one\", \"another\", \"turn\", \"prince\", \"girl\", \"keep\", \"side\", \"broken\", \"wonderful\", \"work\", \"tell\", \"rachel\", \"without\", \"needed\", \"usual\", \"twist\", \"didnt\", \"able\", \"dark\", \"meet\", \"every\", \"developed\", \"notice\", \"looking\", \"humanity\", \"character\", \"much\", \"lot\", \"reader\", \"took\", \"think\", \"way\", \"love\", \"enjoyed\", \"get\", \"could\", \"hero\", \"actually\", \"writing\", \"point\", \"part\", \"soon\", \"feel\", \"person\", \"better\", \"made\", \"third\", \"mind\", \"direction\", \"absolutely\", \"plan\", \"quick\", \"theme\", \"created\", \"bloody\", \"murder\", \"didnt\", \"nice\", \"developed\", \"able\", \"humanity\", \"notice\", \"meet\", \"looking\", \"ive\", \"guess\", \"glad\", \"three\", \"every\", \"book\", \"well\", \"time\", \"something\", \"worth\", \"interesting\", \"evil\", \"loved\", \"tale\", \"written\", \"world\", \"crawford\", \"certainly\", \"begin\", \"admission\", \"devilish\", \"knieval\", \"number\", \"played\", \"price\", \"reference\", \"still\", \"throw\", \"trail\", \"year\", \"he\", \"sanderson\", \"barnes\", \"review\", \"fully\", \"ive\", \"developed\", \"notice\", \"able\", \"meet\", \"every\", \"didnt\", \"looking\", \"really\", \"hill\", \"bit\", \"im\", \"take\", \"new\", \"little\", \"series\", \"perfect\", \"next\", \"doesnt\", \"thriller\", \"fantasy\", \"coming\", \"right\", \"like\", \"devil\", \"full\", \"start\", \"action\", \"fact\", \"kind\", \"light\", \"particularly\", \"superhero\", \"attention\", \"felt\", \"become\", \"rest\", \"forward\", \"looking\", \"work\", \"notice\", \"able\", \"every\", \"humanity\", \"developed\", \"didnt\", \"meet\", \"dark\", \"needed\", \"usual\", \"good\", \"novel\", \"writer\", \"star\", \"enjoy\", \"first\", \"beautiful\", \"make\", \"thought\", \"dont\", \"even\", \"reading\", \"page\", \"although\", \"tension\", \"life\", \"enough\", \"isnt\", \"middle\", \"adventure\", \"five\", \"together\", \"every\", \"word\", \"dark\", \"line\", \"conflict\", \"author\", \"duncan\", \"tell\", \"thick\", \"narrator\", \"yet\", \"abbott\", \"hawkins\", \"megan\", \"notice\", \"developed\", \"able\", \"paula\", \"meet\", \"humanity\", \"involved\", \"remained\", \"didnt\", \"looking\", \"three\", \"work\"], \"Freq\": [24.0, 21.0, 18.0, 16.0, 7.0, 8.0, 7.0, 6.0, 7.0, 6.0, 7.0, 8.0, 6.0, 6.0, 6.0, 6.0, 6.0, 8.0, 5.0, 6.0, 5.0, 6.0, 5.0, 5.0, 5.0, 6.0, 5.0, 4.0, 4.0, 4.0, 23.730787248330397, 7.690020967606215, 5.324504726659562, 5.406993738196723, 5.283375328965467, 5.808585986833718, 3.93879208053473, 3.635066682491417, 3.388769718958349, 2.901170915946515, 2.66366514419767, 3.7125362490207676, 3.836878623073608, 2.3574655055894755, 2.486306423132158, 2.228260440071648, 1.230612095230853, 1.7703991667629317, 0.542265726516604, 0.5575166718310981, 0.35745329952800364, 0.9442840915856295, 1.4202608937484513, 2.1265117320832703, 0.7817127601265441, 1.3426732206708947, 1.5108166325026327, 1.4966678345076967, 1.4966678345076967, 0.5052313693696266, 2.1406032259137735, 2.231378352995158, 1.7470094059257253, 1.728243957892741, 1.8512565088506208, 1.9776423427438568, 1.6731854836946598, 1.5358130755083088, 1.4544951345408044, 15.814105109608958, 8.188702937375867, 6.85857576981125, 5.8684908218534755, 7.098127075818964, 4.620687646761781, 3.9542633206409694, 2.8414113534174095, 2.86981907066612, 3.411210720084053, 2.2038861067044615, 2.040814371128892, 2.5009244878167944, 1.6776111957327529, 0.9715768456565335, 3.235916044464032, 0.8283945557838028, 0.8110352882315425, 0.7165833963063606, 5.037030077359257, 0.598751633577552, 0.5619112272662694, 0.5977860640478441, 0.786625785484534, 0.5343869433384616, 0.33002987319143756, 0.291097157050175, 1.7329707707156006, 0.2991926855912892, 1.272865478811992, 1.044366681446245, 1.93070773901683, 1.0367184027507443, 2.09877320291998, 1.8826580951579213, 1.501036803516807, 1.5633557086316043, 1.388964722768131, 1.3507689732817207, 1.1899798967640889, 1.1334895608273916, 1.1625868393106749, 1.1489645586533723, 1.218613000364793, 21.079065322882307, 17.490547267617607, 6.25568103045382, 3.457974736500356, 3.2456953961351083, 7.255406810585674, 3.1578941512444256, 1.8177970223887674, 2.3927443421435615, 1.1293883877038051, 0.978935248131058, 3.940184890606443, 1.1538461848940993, 1.1806621974224991, 2.2138757067450348, 2.2138757067450348, 2.2138757067450348, 2.2138757067450348, 2.2138757067450348, 2.2138757067450348, 2.2138757067450348, 2.2138757067450348, 2.2138757067450348, 2.2138757067450348, 0.5376198533693638, 2.4152045768940322, 0.967307051613379, 0.2535052893944342, 0.3047411661306513, 0.22814871941035775, 1.4702805186335994, 1.871834293315616, 1.5637453605034088, 1.4603039994598, 1.2232722297693708, 1.2259533098056576, 1.2081598453764761, 1.1936741514975175, 5.263605724929183, 5.722833737111779, 6.277399271280387, 6.027101873276196, 5.247741771838724, 5.936555513534562, 3.973799479102418, 3.032282716130984, 3.433948864740289, 2.648129547220242, 2.6498427907299114, 4.924160468595231, 3.1966761342692713, 3.8936747561103315, 1.9248966033535932, 1.247394946348971, 1.6699204887495347, 0.5666488823463219, 0.45384631210422127, 0.30818236112182945, 0.8578238397358748, 0.8578238397358748, 0.8578238397358748, 0.8578238397358748, 0.8578238397358748, 0.9272163460871996, 0.46895158742808785, 0.3215004642191009, 0.5276915206312819, 1.0186873763579611, 1.4114662229110921, 1.3641507870102387, 1.4657510425014029, 1.472004262391508, 1.3568476339928908, 1.208298877447885, 1.418697098880793, 1.3168681202278798, 1.1424892381632297, 1.1239674188690838, 0.9672222865606739, 0.9672222865606739, 7.298200725051727, 6.573615893618492, 5.739441068279556, 6.12759013410282, 3.1838643479488153, 2.6079002875830994, 3.356632667195584, 2.2625265893769417, 1.7394654957326807, 1.928337325027277, 1.4861898732679506, 1.14293035059182, 1.0901886795740978, 1.0561846988324226, 1.1303423278467644, 2.3838558743599787, 0.5976116516435395, 0.3717572159850576, 0.5643896704254918, 0.2910031619669931, 0.332513939640225, 1.564366548446797, 2.2780294468747115, 0.4198889609102667, 1.7109560056987552, 0.3821058850833458, 0.22102865796244375, 0.19080176401636958, 0.2105334153467143, 0.5316761185668972, 0.48866462669016886, 0.9336098314972646, 0.7665160848674725, 0.9170807538044502, 0.9170807538044502, 0.9170807538044502, 1.4638221441128725, 1.5767760706130551, 1.4738256404051722, 0.9170807538044502, 1.183815459067611, 1.1371119401590444, 0.9715809907653815, 0.9679691055596723, 1.1422038241396333, 1.0426053084149722, 0.9499605351177155, 1.0212288836790715], \"Total\": [24.0, 21.0, 18.0, 16.0, 7.0, 8.0, 7.0, 6.0, 7.0, 6.0, 7.0, 8.0, 6.0, 6.0, 6.0, 6.0, 6.0, 8.0, 5.0, 6.0, 5.0, 6.0, 5.0, 5.0, 5.0, 6.0, 5.0, 4.0, 4.0, 4.0, 24.243156289219844, 8.427531566405019, 5.84178457573622, 5.949378214235903, 5.820918674927496, 6.484492502716541, 4.443620033813964, 4.139143823265248, 3.9616868707376565, 3.443390327455203, 3.215587341512734, 4.50729798245577, 4.667915798289824, 2.8716393483045124, 3.0407583630443926, 2.7541934124587613, 1.7919550690689185, 2.8279453276998803, 1.0430073870199859, 1.1849772210761222, 0.9958446657874156, 2.6526654516980894, 4.150544780762981, 6.4691752627909604, 2.445036947575787, 4.358760027358772, 4.914719518134416, 4.907569613988277, 4.907569613988277, 1.662309778978635, 7.738542754674593, 8.52017035040956, 6.585062720296225, 6.666785607661083, 7.930699899888673, 8.9437230084733, 7.729859739443948, 6.534327731613612, 6.409833144157988, 16.344918203562138, 8.71510914031003, 7.435834704071296, 6.3990130036451776, 7.763085766476429, 5.152431277598209, 4.491904258429796, 3.351072423354526, 3.389594645304808, 4.046238192463878, 2.724593461062165, 2.566326282866537, 3.178650932915308, 2.259376529469582, 1.5185381864783873, 5.210969928400237, 1.3682090865870313, 1.342682355821262, 1.2401970266537687, 8.756090283534906, 1.1227293079223903, 1.1541951330847158, 1.4652082496354273, 2.0025756330829227, 1.44639064392729, 0.9177800792996531, 0.8306765903357282, 5.111074687070721, 0.9222207443255125, 3.940921005304329, 3.7132802931747797, 7.738542754674593, 3.7061233790737598, 8.9437230084733, 8.52017035040956, 6.409833144157988, 7.729859739443948, 6.666785607661083, 6.534327731613612, 5.244928240373468, 4.62783595502927, 5.048799937767071, 5.04021579655794, 7.930699899888673, 21.60613720027906, 18.037969004003706, 6.823806132567824, 3.9994759293438906, 3.848086527269253, 8.726836489125043, 3.8708775251226233, 2.3575274317040873, 3.1208869859804516, 1.6790852343281288, 1.5020545285193867, 6.076389616170143, 1.7877629860544362, 1.965419395990751, 3.8367899793222144, 3.8367899793222144, 3.8367899793222144, 3.8367899793222144, 3.8367899793222144, 3.8367899793222144, 3.8367899793222144, 3.8367899793222144, 3.8367899793222144, 3.8367899793222144, 1.0679830291665724, 5.125918544872485, 2.8984591103027286, 0.7830513767892926, 1.0271681623543742, 0.7874338098775044, 5.244928240373468, 8.9437230084733, 7.729859739443948, 8.52017035040956, 6.666785607661083, 7.930699899888673, 7.738542754674593, 6.534327731613612, 5.793976791968096, 6.340637780259277, 6.996361974562716, 6.742965820384763, 5.891266656962619, 6.678166725069804, 4.650310241752309, 3.6485792265153494, 4.1462319001915935, 3.295322514252187, 3.3323789566226107, 6.235299364318337, 4.063076979670961, 4.993207261409212, 2.5356430931227347, 1.768374145647457, 2.6414739362945276, 1.1305871637700757, 0.9892217952997501, 0.8321233925128486, 2.618186017224898, 2.618186017224898, 2.618186017224898, 2.618186017224898, 2.618186017224898, 3.3478020290740913, 1.7797675798190593, 1.336488582345304, 2.2839115264655283, 4.656078925655779, 6.534327731613612, 6.4691752627909604, 7.729859739443948, 8.52017035040956, 7.930699899888673, 6.409833144157988, 8.9437230084733, 7.738542754674593, 6.666785607661083, 6.585062720296225, 4.907569613988277, 4.907569613988277, 7.828360437804858, 7.11011462846189, 6.312149104806595, 6.953394561634448, 3.8490700298739364, 3.155983128472271, 4.2336166655571335, 2.8721373101213428, 2.2776226100579207, 2.606991853314396, 2.0318336043358003, 1.6637695809313144, 1.6085895569514748, 1.5830724941208576, 1.8098500399893585, 4.127575581593391, 1.1176487775742228, 0.9595666303280328, 1.5515698324539735, 0.8380107879581686, 0.983067615442962, 4.635788820282631, 7.930699899888673, 1.5620928434838366, 6.585062720296225, 1.5710415156415227, 0.9679765784683189, 0.8496701891261301, 0.9560114177645339, 2.445036947575787, 2.2642807721897036, 4.529589664301824, 3.675204742482738, 4.499573035067754, 4.499573035067754, 4.499573035067754, 7.729859739443948, 8.9437230084733, 8.52017035040956, 4.499573035067754, 6.666785607661083, 6.409833144157988, 5.011787272339077, 5.023344621053578, 7.738542754674593, 6.534327731613612, 5.04021579655794, 6.4691752627909604], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.713, -3.8399, -4.2075, -4.1921, -4.2152, -4.1204, -4.5089, -4.5892, -4.6593, -4.8147, -4.9001, -4.5681, -4.5351, -5.0222, -4.969, -5.0786, -5.6723, -5.3086, -6.4918, -6.464, -6.9085, -5.9371, -5.5289, -5.1253, -6.1261, -5.5851, -5.4671, -5.4765, -5.4765, -6.5625, -5.1187, -5.0772, -5.3219, -5.3327, -5.2639, -5.1979, -5.3651, -5.4507, -5.5051, -3.0349, -3.6931, -3.8703, -4.0262, -3.836, -4.2653, -4.421, -4.7515, -4.7416, -4.5688, -5.0056, -5.0825, -4.8792, -5.2785, -5.8247, -4.6215, -5.9841, -6.0053, -6.1291, -4.179, -6.3087, -6.3722, -6.3104, -6.0358, -6.4225, -6.9044, -7.0299, -5.246, -7.0025, -5.5546, -5.7524, -5.1379, -5.7598, -5.0545, -5.1631, -5.3897, -5.349, -5.4673, -5.4952, -5.6219, -5.6705, -5.6452, -5.657, -5.5981, -2.6912, -2.8779, -3.906, -4.4988, -4.5622, -3.7578, -4.5896, -5.1419, -4.8671, -5.6179, -5.7608, -4.3683, -5.5964, -5.5735, -4.9448, -4.9448, -4.9448, -4.9448, -4.9448, -4.9448, -4.9448, -4.9448, -4.9448, -4.9448, -6.3601, -4.8577, -5.7728, -7.1119, -6.9278, -7.2173, -5.3541, -5.1126, -5.2924, -5.3609, -5.538, -5.5358, -5.5504, -5.5625, -3.9873, -3.9036, -3.8112, -3.8518, -3.9903, -3.867, -4.2684, -4.5388, -4.4144, -4.6743, -4.6736, -4.054, -4.486, -4.2888, -4.9932, -5.4271, -5.1353, -6.2161, -6.4381, -6.8252, -5.8015, -5.8015, -5.8015, -5.8015, -5.8015, -5.7237, -6.4054, -6.7829, -6.2874, -5.6296, -5.3035, -5.3376, -5.2657, -5.2615, -5.3429, -5.4589, -5.2984, -5.3729, -5.5149, -5.5312, -5.6814, -5.6814, -3.617, -3.7215, -3.8572, -3.7918, -4.4465, -4.646, -4.3937, -4.7881, -5.051, -4.9479, -5.2084, -5.471, -5.5182, -5.5499, -5.4821, -4.7359, -6.1194, -6.5941, -6.1766, -6.839, -6.7057, -5.1571, -4.7813, -6.4724, -5.0675, -6.5666, -7.1141, -7.2611, -7.1627, -6.2363, -6.3207, -5.6733, -5.8705, -5.6911, -5.6911, -5.6911, -5.2235, -5.1492, -5.2167, -5.6911, -5.4358, -5.4761, -5.6334, -5.6371, -5.4716, -5.5629, -5.6559, -5.5836], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.4468, 1.3766, 1.3754, 1.3726, 1.3713, 1.3581, 1.3476, 1.3383, 1.312, 1.2968, 1.2799, 1.2742, 1.2721, 1.2709, 1.2669, 1.2563, 1.0924, 0.9998, 0.8141, 0.7142, 0.4436, 0.4353, 0.3958, 0.3556, 0.3278, 0.2906, 0.2886, 0.2806, 0.2806, 0.2772, 0.183, 0.1283, 0.1413, 0.1181, 0.0133, -0.0409, -0.0622, 0.0202, -0.015, 1.5191, 1.4898, 1.4713, 1.4656, 1.4626, 1.4432, 1.4246, 1.3871, 1.3857, 1.3814, 1.34, 1.323, 1.3123, 1.2544, 1.1055, 1.0757, 1.0503, 1.048, 1.0036, 0.9992, 0.9234, 0.8323, 0.6556, 0.6177, 0.5564, 0.5293, 0.5035, 0.4705, 0.4264, 0.422, 0.2836, 0.1638, 0.2782, 0.1025, 0.0424, 0.1004, -0.0461, -0.0165, -0.0243, 0.0688, 0.1453, 0.0836, 0.0735, -0.3209, 1.5837, 1.5776, 1.5215, 1.4629, 1.4382, 1.4238, 1.4048, 1.3484, 1.3427, 1.2118, 1.1803, 1.1752, 1.1706, 1.0988, 1.0585, 1.0585, 1.0585, 1.0585, 1.0585, 1.0585, 1.0585, 1.0585, 1.0585, 1.0585, 0.922, 0.8559, 0.511, 0.4806, 0.3933, 0.3696, 0.3366, 0.0444, 0.0104, -0.1554, -0.0872, -0.2586, -0.2487, -0.0916, 1.6038, 1.5973, 1.5914, 1.5876, 1.5842, 1.5821, 1.5426, 1.5148, 1.5113, 1.4812, 1.4706, 1.4638, 1.46, 1.4511, 1.4243, 1.3508, 1.2413, 1.0091, 0.9207, 0.7065, 0.584, 0.584, 0.584, 0.584, 0.584, 0.416, 0.3661, 0.275, 0.2347, 0.1802, 0.1674, 0.1433, 0.0371, -0.056, -0.0657, 0.0312, -0.1414, -0.0711, -0.0641, -0.0681, 0.0757, 0.0757, 1.6732, 1.6649, 1.6482, 1.6169, 1.5536, 1.5526, 1.5112, 1.5048, 1.4738, 1.4418, 1.4306, 1.3679, 1.3543, 1.3386, 1.2726, 1.1944, 1.1173, 0.7951, 0.7321, 0.6857, 0.6594, 0.657, 0.4959, 0.4296, 0.3956, 0.3296, 0.2664, 0.2497, 0.2302, 0.2176, 0.21, 0.164, 0.1758, 0.1528, 0.1528, 0.1528, 0.0793, 0.0078, -0.0112, 0.1528, 0.015, 0.014, 0.1027, 0.0967, -0.1699, -0.092, 0.0746, -0.1027]}, \"token.table\": {\"Topic\": [1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 2, 3, 1, 5, 1, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 4, 1, 2, 3, 5, 3, 1, 2, 3, 2, 4, 2, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 3, 1, 2, 3, 4, 5, 2, 4, 5, 5, 2, 5, 5, 1, 2, 3, 4, 5, 3, 2, 4, 4, 2, 5, 1, 2, 3, 4, 5, 4, 1, 2, 1, 1, 2, 3, 4, 5, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 4, 1, 2, 3, 4, 5, 4, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 1, 2, 4, 3, 1, 5, 2, 4, 4, 1, 4, 1, 2, 3, 4, 5, 2, 2, 3, 2, 1, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 2, 2, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 3, 1, 5, 1, 2, 2, 4, 1, 2, 3, 4, 5, 4, 2, 3, 2, 3, 1, 1, 2, 3, 4, 5, 1, 2, 5, 4, 3, 1, 2, 3, 4, 5, 4, 4, 1, 3, 4, 1, 4, 3, 2, 5, 3, 1, 2, 4, 4, 3, 1, 5, 5, 1, 2, 3, 4, 5, 2, 2, 5, 1, 2, 3, 4, 5, 4, 3, 3, 1, 2, 3, 4, 5, 2, 3, 1, 1, 1, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 3, 1, 5, 2, 3, 3, 1, 2, 3, 4, 5], \"Freq\": [0.22224330891096253, 0.22224330891096253, 0.22224330891096253, 0.22224330891096253, 0.22224330891096253, 0.23473709066202664, 0.23473709066202664, 0.11736854533101332, 0.11736854533101332, 0.11736854533101332, 0.6913761535989789, 0.9437966179093916, 0.5212690845156213, 0.8874496462336461, 0.6316830111784232, 0.7261654141473429, 0.29870344522031733, 0.29870344522031733, 0.29870344522031733, 0.29870344522031733, 0.7086139905879285, 0.5087972582543425, 0.11420622305373167, 0.5710311152686584, 0.11420622305373167, 0.11420622305373167, 0.11420622305373167, 0.8575885612858116, 0.2537477911011254, 0.2537477911011254, 0.2537477911011254, 0.2537477911011254, 0.9719460635346131, 0.3769793131507991, 0.3769793131507991, 0.5593582638194025, 0.9788975264809238, 0.8010883167047019, 0.7340544666874129, 0.16457140887392355, 0.16457140887392355, 0.6582856354956942, 0.30371768424250195, 0.15185884212125098, 0.15185884212125098, 0.15185884212125098, 0.30371768424250195, 0.22362052113031633, 0.22362052113031633, 0.22362052113031633, 0.11181026056515816, 0.22362052113031633, 0.7571530320702727, 0.5212690845156213, 0.2584465917425949, 0.2584465917425949, 0.12922329587129744, 0.12922329587129744, 0.12922329587129744, 0.49935691989846154, 0.900257755510652, 0.7671677214707451, 0.7794090460074728, 0.8850615822619186, 0.894735466154608, 0.4921662865827523, 0.25218455183609645, 0.12609227591804822, 0.12609227591804822, 0.12609227591804822, 0.25218455183609645, 0.7750180625787081, 0.38194383188247755, 0.38194383188247755, 0.7383566727901247, 0.7447777917572637, 0.9505754238465215, 0.21477299160240426, 0.21477299160240426, 0.21477299160240426, 0.21477299160240426, 0.21477299160240426, 0.8844961556660369, 0.8559028384523862, 0.7414294110483911, 0.9587659804185436, 0.19806686981585356, 0.19806686981585356, 0.19806686981585356, 0.19806686981585356, 0.19806686981585356, 0.8941846834485897, 0.900166974125102, 0.2160837181173755, 0.2160837181173755, 0.2160837181173755, 0.2160837181173755, 0.2160837181173755, 0.22224330891096253, 0.22224330891096253, 0.22224330891096253, 0.22224330891096253, 0.22224330891096253, 0.19508698611691974, 0.19508698611691974, 0.3901739722338395, 0.19508698611691974, 0.19508698611691974, 0.7793241308996915, 0.9462770478200463, 0.15601030128395996, 0.3120206025679199, 0.15601030128395996, 0.15601030128395996, 0.15601030128395996, 0.8898161669248431, 0.8021234279710704, 0.19952961801055952, 0.19952961801055952, 0.19952961801055952, 0.19952961801055952, 0.19952961801055952, 0.19066037782983938, 0.19066037782983938, 0.19066037782983938, 0.19066037782983938, 0.19066037782983938, 0.8438980785570397, 0.8569134861998737, 0.38194383188247755, 0.38194383188247755, 0.5212690845156213, 0.24227297119874042, 0.48454594239748083, 0.38194383188247755, 0.38194383188247755, 0.5654911900071173, 0.8589709424281347, 0.8601576651997175, 0.3060758630645103, 0.15303793153225514, 0.15303793153225514, 0.15303793153225514, 0.15303793153225514, 0.9413872522162621, 0.895235799468908, 0.8483464383506001, 0.8906866445399018, 0.9329555323441119, 0.6963455378515673, 0.8712343692436154, 0.2999946477507415, 0.14999732387537076, 0.14999732387537076, 0.14999732387537076, 0.14999732387537076, 0.22224330891096253, 0.22224330891096253, 0.22224330891096253, 0.22224330891096253, 0.22224330891096253, 0.6445085352158421, 0.6824968397828908, 0.9179460487760924, 0.2693036671209703, 0.2693036671209703, 0.2693036671209703, 0.2693036671209703, 0.2693036671209703, 0.8404239602780348, 0.2207705496771829, 0.2207705496771829, 0.2207705496771829, 0.2207705496771829, 0.2207705496771829, 0.20376684971511214, 0.20376684971511214, 0.20376684971511214, 0.20376684971511214, 0.20376684971511214, 0.8984501655935049, 0.9103813016859732, 0.26982372083088113, 0.26982372083088113, 0.26982372083088113, 0.26982372083088113, 0.26982372083088113, 0.2587369069317513, 0.2587369069317513, 0.2587369069317513, 0.12936845346587564, 0.12936845346587564, 0.9845129601678854, 0.5212690845156213, 0.6577306583472189, 0.6216626209454911, 0.19190285373744212, 0.5757085612123264, 0.38194383188247755, 0.38194383188247755, 0.22224330891096253, 0.22224330891096253, 0.22224330891096253, 0.22224330891096253, 0.22224330891096253, 0.7235485308627752, 0.8063234941774896, 0.5212690845156213, 0.6585280560636284, 0.5212690845156213, 0.7072272509690657, 0.22942304548157438, 0.22942304548157438, 0.22942304548157438, 0.22942304548157438, 0.22942304548157438, 0.9899701059416934, 0.9376446018443968, 0.6010447669323526, 0.8629651411326419, 0.5212690845156213, 0.1990705546676715, 0.1990705546676715, 0.1990705546676715, 0.1990705546676715, 0.1990705546676715, 0.4378453317530876, 0.7887545394004678, 0.34501090474088325, 0.34501090474088325, 0.34501090474088325, 0.925284437831708, 0.8222378667833429, 0.7500982761239287, 0.7308824431903744, 0.8628878955187113, 0.5212690845156213, 0.9663834287460248, 0.38194383188247755, 0.38194383188247755, 0.8487139169113536, 0.6408434553972431, 0.4089917745380016, 0.4089917745380016, 0.5525319655798001, 0.19565356822698357, 0.39130713645396714, 0.19565356822698357, 0.19565356822698357, 0.19565356822698357, 0.9704156602222039, 0.866404623737572, 0.8781085993649929, 0.198404203384093, 0.198404203384093, 0.198404203384093, 0.198404203384093, 0.198404203384093, 0.8018861177079373, 0.5212690845156213, 0.8792746868003675, 0.21571301859669975, 0.21571301859669975, 0.21571301859669975, 0.21571301859669975, 0.4314260371933995, 0.9017032930678563, 0.5212690845156213, 0.5580497063018381, 0.6015725905278769, 0.7572531847882786, 0.20376684971511214, 0.20376684971511214, 0.20376684971511214, 0.20376684971511214, 0.20376684971511214, 0.9492696570714367, 0.890490929875307, 0.942456437098139, 0.40694082187607367, 0.20347041093803683, 0.20347041093803683, 0.20347041093803683, 0.20347041093803683, 0.2409322276523356, 0.2409322276523356, 0.2409322276523356, 0.2409322276523356, 0.2409322276523356, 0.3091584195443719, 0.15457920977218595, 0.15457920977218595, 0.15457920977218595, 0.15457920977218595, 0.6657547918621339, 0.7796082491234709, 0.6964662889094516, 0.9505478879500963, 0.885199954019849, 0.5955623809652172, 0.9363444668033493, 0.27209368458870203, 0.27209368458870203, 0.27209368458870203, 0.27209368458870203, 0.27209368458870203], \"Term\": [\"abbott\", \"abbott\", \"abbott\", \"abbott\", \"abbott\", \"able\", \"able\", \"able\", \"able\", \"able\", \"absolutely\", \"actually\", \"admission\", \"also\", \"although\", \"another\", \"attention\", \"attention\", \"attention\", \"attention\", \"beautiful\", \"begin\", \"better\", \"better\", \"better\", \"better\", \"better\", \"bit\", \"bloody\", \"bloody\", \"bloody\", \"bloody\", \"book\", \"broken\", \"broken\", \"certainly\", \"character\", \"coming\", \"could\", \"crawford\", \"crawford\", \"crawford\", \"dark\", \"dark\", \"dark\", \"dark\", \"dark\", \"developed\", \"developed\", \"developed\", \"developed\", \"developed\", \"devil\", \"devilish\", \"didnt\", \"didnt\", \"didnt\", \"didnt\", \"didnt\", \"direction\", \"doesnt\", \"dont\", \"enjoy\", \"enjoyed\", \"enough\", \"even\", \"every\", \"every\", \"every\", \"every\", \"every\", \"evil\", \"fact\", \"fact\", \"fantasy\", \"feel\", \"first\", \"forward\", \"forward\", \"forward\", \"forward\", \"forward\", \"full\", \"fun\", \"get\", \"girl\", \"glad\", \"glad\", \"glad\", \"glad\", \"glad\", \"good\", \"great\", \"guess\", \"guess\", \"guess\", \"guess\", \"guess\", \"hawkins\", \"hawkins\", \"hawkins\", \"hawkins\", \"hawkins\", \"he\", \"he\", \"he\", \"he\", \"he\", \"hero\", \"hill\", \"humanity\", \"humanity\", \"humanity\", \"humanity\", \"humanity\", \"im\", \"interesting\", \"involved\", \"involved\", \"involved\", \"involved\", \"involved\", \"ive\", \"ive\", \"ive\", \"ive\", \"ive\", \"keep\", \"kept\", \"kind\", \"kind\", \"knieval\", \"life\", \"life\", \"light\", \"light\", \"like\", \"liked\", \"little\", \"looking\", \"looking\", \"looking\", \"looking\", \"looking\", \"lot\", \"love\", \"loved\", \"made\", \"magic\", \"make\", \"many\", \"meet\", \"meet\", \"meet\", \"meet\", \"meet\", \"megan\", \"megan\", \"megan\", \"megan\", \"megan\", \"middle\", \"mind\", \"much\", \"murder\", \"murder\", \"murder\", \"murder\", \"murder\", \"mystery\", \"narrator\", \"narrator\", \"narrator\", \"narrator\", \"narrator\", \"needed\", \"needed\", \"needed\", \"needed\", \"needed\", \"new\", \"next\", \"nice\", \"nice\", \"nice\", \"nice\", \"nice\", \"notice\", \"notice\", \"notice\", \"notice\", \"notice\", \"novel\", \"number\", \"one\", \"page\", \"part\", \"part\", \"particularly\", \"particularly\", \"paula\", \"paula\", \"paula\", \"paula\", \"paula\", \"perfect\", \"person\", \"played\", \"point\", \"price\", \"prince\", \"rachel\", \"rachel\", \"rachel\", \"rachel\", \"rachel\", \"read\", \"reader\", \"reading\", \"really\", \"reference\", \"remained\", \"remained\", \"remained\", \"remained\", \"remained\", \"rest\", \"right\", \"sanderson\", \"sanderson\", \"sanderson\", \"see\", \"series\", \"something\", \"soon\", \"star\", \"still\", \"story\", \"superhero\", \"superhero\", \"take\", \"tale\", \"tell\", \"tell\", \"tension\", \"theme\", \"theme\", \"theme\", \"theme\", \"theme\", \"think\", \"third\", \"thought\", \"three\", \"three\", \"three\", \"three\", \"three\", \"thriller\", \"throw\", \"time\", \"together\", \"together\", \"together\", \"together\", \"together\", \"took\", \"trail\", \"turn\", \"twist\", \"two\", \"usual\", \"usual\", \"usual\", \"usual\", \"usual\", \"voice\", \"way\", \"well\", \"without\", \"without\", \"without\", \"without\", \"without\", \"wonderful\", \"wonderful\", \"wonderful\", \"wonderful\", \"wonderful\", \"work\", \"work\", \"work\", \"work\", \"work\", \"world\", \"worth\", \"would\", \"writer\", \"writing\", \"written\", \"year\", \"yet\", \"yet\", \"yet\", \"yet\", \"yet\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 3, 4, 2, 5]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el321751403262719728486253701071\", ldavis_el321751403262719728486253701071_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el321751403262719728486253701071\", ldavis_el321751403262719728486253701071_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el321751403262719728486253701071\", ldavis_el321751403262719728486253701071_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "0     -0.037640 -0.074519       1        1  23.034890\n",
       "2     -0.025259  0.062994       2        1  21.179990\n",
       "3      0.100350 -0.007664       3        1  20.020463\n",
       "1     -0.024585  0.016881       4        1  18.271386\n",
       "4     -0.012865  0.002308       5        1  17.493271, topic_info=          Term       Freq      Total Category  logprob  loglift\n",
       "13        read  24.000000  24.000000  Default  30.0000  30.0000\n",
       "0         book  21.000000  21.000000  Default  29.0000  29.0000\n",
       "37        well  18.000000  18.000000  Default  28.0000  28.0000\n",
       "16   character  16.000000  16.000000  Default  27.0000  27.0000\n",
       "46        good   7.000000   7.000000  Default  26.0000  26.0000\n",
       "..         ...        ...        ...      ...      ...      ...\n",
       "106   remained   0.967969   5.023345   Topic5  -5.6371   0.0967\n",
       "711      didnt   1.142204   7.738543   Topic5  -5.4716  -0.1699\n",
       "762    looking   1.042605   6.534328   Topic5  -5.5629  -0.0920\n",
       "232      three   0.949961   5.040216   Topic5  -5.6559   0.0746\n",
       "665       work   1.021229   6.469175   Topic5  -5.5836  -0.1027\n",
       "\n",
       "[241 rows x 6 columns], token_table=      Topic      Freq    Term\n",
       "term                         \n",
       "843       1  0.222243  abbott\n",
       "843       2  0.222243  abbott\n",
       "843       3  0.222243  abbott\n",
       "843       4  0.222243  abbott\n",
       "843       5  0.222243  abbott\n",
       "...     ...       ...     ...\n",
       "28        1  0.272094     yet\n",
       "28        2  0.272094     yet\n",
       "28        3  0.272094     yet\n",
       "28        4  0.272094     yet\n",
       "28        5  0.272094     yet\n",
       "\n",
       "[306 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 3, 4, 2, 5])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(best_model, corpus, dictionary)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best coherence: 0.5279284985362422\n",
      "Best num topics: 3\n",
      "Best num passes: 5\n",
      "Best chunksize: 5\n",
      "[(0, '0.032*\"little\" + 0.025*\"unfortunately\" + 0.025*\"cast\" + 0.025*\"justice\" + 0.025*\"killer\" + 0.018*\"felt\" + 0.018*\"like\" + 0.014*\"got\" + 0.014*\"time\" + 0.013*\"much\"'), (1, '0.019*\"feel\" + 0.019*\"get\" + 0.016*\"conclusion\" + 0.016*\"got\" + 0.014*\"character\" + 0.014*\"didnt\" + 0.012*\"even\" + 0.012*\"ethan\" + 0.011*\"interesting\" + 0.010*\"reading\"'), (2, '0.040*\"book\" + 0.028*\"first\" + 0.025*\"writing\" + 0.023*\"part\" + 0.022*\"sequel\" + 0.020*\"pevels\" + 0.020*\"revelation\" + 0.020*\"ignored\" + 0.020*\"flaw\" + 0.020*\"certain\"')]\n"
     ]
    }
   ],
   "source": [
    "# Call the find_best_hyperparameter function with the 'data_words_neg' variable as input to get the best hyperparameters and resulting model\n",
    "best_coherence, best_num_topics, best_num_passes, best_chunksize, best_model, corpus, dictionary = find_best_hyperparameter(data_words_neg)\n",
    "# Print the best hyperparameters and coherence score\n",
    "print('Best coherence:', best_coherence)\n",
    "print('Best num topics:', best_num_topics)\n",
    "print('Best num passes:', best_num_passes)\n",
    "print('Best chunksize:', best_chunksize)\n",
    "# Print the top topics and their associated keywords for the resulting model\n",
    "print(best_model.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oyuesan/opt/anaconda3/lib/python3.9/site-packages/pyLDAvis/_prepare.py:243: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  default_term_info = default_term_info.sort_values(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el321751403249031809924596997456\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el321751403249031809924596997456_data = {\"mdsDat\": {\"x\": [-0.1528059436545528, 0.11515544086463783, 0.03765050278991507], \"y\": [-0.02685915843202627, -0.06600224445726056, 0.09286140288928683], \"topics\": [1, 2, 3], \"cluster\": [1, 1, 1], \"Freq\": [34.259305980295885, 34.16604057019516, 31.574653449508954]}, \"tinfo\": {\"Term\": [\"book\", \"little\", \"first\", \"unfortunately\", \"killer\", \"justice\", \"cast\", \"writing\", \"part\", \"sequel\", \"feel\", \"get\", \"stronger\", \"certain\", \"thanks\", \"flaw\", \"pevels\", \"largely\", \"revelation\", \"overlooked\", \"ignored\", \"like\", \"felt\", \"conclusion\", \"didnt\", \"theyre\", \"got\", \"made\", \"ethan\", \"scene\", \"book\", \"first\", \"writing\", \"sequel\", \"certain\", \"flaw\", \"ignored\", \"largely\", \"overlooked\", \"pevels\", \"revelation\", \"stronger\", \"thanks\", \"part\", \"theyre\", \"though\", \"enough\", \"sort\", \"found\", \"hard\", \"something\", \"dealt\", \"detail\", \"different\", \"done\", \"fascination\", \"husband\", \"ohlsson\", \"relationship\", \"seems\", \"character\", \"interesting\", \"little\", \"unfortunately\", \"cast\", \"justice\", \"killer\", \"like\", \"made\", \"scene\", \"felt\", \"cheesier\", \"story\", \"forced\", \"precociousness\", \"every\", \"disappointed\", \"doesnt\", \"im\", \"one\", \"sure\", \"wasnt\", \"absence\", \"cell\", \"dropping\", \"fix\", \"highlight\", \"phone\", \"reference\", \"simply\", \"someone\", \"technology\", \"time\", \"page\", \"much\", \"got\", \"left\", \"good\", \"place\", \"character\", \"feel\", \"get\", \"conclusion\", \"didnt\", \"ethan\", \"however\", \"honest\", \"reading\", \"make\", \"finish\", \"merely\", \"skimmed\", \"attached\", \"find\", \"somewhat\", \"stereotype\", \"started\", \"okay\", \"obsession\", \"xd\", \"cait\", \"confusing\", \"corpse\", \"finding\", \"garnet\", \"laid\", \"lost\", \"rather\", \"lee\", \"fresh\", \"mind\", \"even\", \"got\", \"interesting\", \"character\"], \"Freq\": [8.0, 6.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.0, 4.0, 3.0, 2.0, 3.0, 5.0, 2.0, 2.0, 2.0, 7.75156298086252, 5.41228743011717, 4.931259103045425, 4.183796805809302, 3.8181691182792115, 3.8181691182792115, 3.8181691182792115, 3.8181691182792115, 3.8181691182792115, 3.8181691182792115, 3.8181691182792115, 3.8181691182792115, 3.8181691182792115, 4.549874525097086, 2.745492960543079, 1.7319705156700353, 1.6283023051821832, 1.6240867789703695, 1.3405335429543397, 1.324412130424171, 1.357624636673487, 1.2715401710424181, 1.2715401710424181, 1.2715401710424181, 1.2715401710424181, 1.2715401710424181, 1.2715401710424181, 1.2715401710424181, 1.2715401710424181, 1.2715401710424181, 2.0185919858607093, 1.3237248026273085, 6.268406408017956, 4.92278150741484, 4.853565153042504, 4.853565153042504, 4.853565153042504, 3.390566875793324, 2.4362518198685024, 2.351966044852655, 3.501680372636738, 1.8362333898659644, 2.214540809714518, 1.6162457467017828, 1.6162457467017828, 2.3519831542542673, 1.5509886879615726, 1.54495717364571, 1.4379831614482481, 1.3945984015316941, 1.3687820254383982, 1.3859258259532168, 1.2771140839235944, 1.2771140839235944, 1.2771140839235944, 1.2771140839235944, 1.2771140839235944, 1.2771140839235944, 1.2771140839235944, 1.2771140839235944, 1.2771140839235944, 1.2771140839235944, 2.651128434523581, 1.704815895980397, 2.4363870741907245, 2.70179495576647, 1.3093635950232385, 1.3253832178026252, 1.6162538511551783, 1.4512695122952763, 3.4766159114287434, 3.432621750440428, 2.8802645619229974, 2.44794269691627, 2.108660078893597, 1.6670404307883837, 1.3470480122219324, 1.753111541668019, 1.6768921229528297, 1.2363926926866935, 1.2363926926866935, 1.2363926926866935, 1.2363926926866935, 1.2363926926866935, 1.2363926926866935, 1.2363926926866935, 1.5112944499864194, 1.7498729711735892, 1.0935076215709807, 1.0799945205761454, 1.1466560952206244, 1.1466560952206244, 1.1466560952206244, 1.1466560952206244, 1.1466560952206244, 1.1466560952206244, 1.1466560952206244, 1.1466560952206244, 0.7956353651556215, 1.5441270437053876, 1.5441270437053876, 2.113839827704222, 2.863850345551291, 2.01320313867272, 2.54413113663982], \"Total\": [8.0, 6.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.0, 4.0, 3.0, 2.0, 3.0, 5.0, 2.0, 2.0, 2.0, 8.287820871513793, 5.870866638552888, 5.379564708714543, 4.641347622158555, 4.266483130229934, 4.266483130229934, 4.266483130229934, 4.266483130229934, 4.266483130229934, 4.266483130229934, 4.266483130229934, 4.266483130229934, 4.266483130229934, 5.1745071547389765, 3.2090381682420133, 2.18832450731364, 2.0962148641898266, 2.100876556239315, 1.7932032715431387, 1.7749429904569896, 1.8304570260926236, 1.719849502939785, 1.719849502939785, 1.719849502939785, 1.719849502939785, 1.719849502939785, 1.719849502939785, 1.719849502939785, 1.719849502939785, 1.719849502939785, 6.013992634795805, 3.5409283569860346, 6.673499557548367, 5.3280506856987415, 5.258657088563462, 5.258657088563462, 5.258657088563462, 3.86069375262932, 2.841341835611388, 2.7570563857245656, 4.106165590603183, 2.2413240573850906, 2.7303250022689296, 2.0213451691140825, 2.0213451691140825, 2.9480486417218614, 1.9706212988065868, 1.9650321504977646, 1.8430731546173096, 1.802551760367585, 1.7738720411812838, 1.8179325089135752, 1.6822043718988375, 1.6822043718988375, 1.6822043718988375, 1.6822043718988375, 1.6822043718988375, 1.6822043718988375, 1.6822043718988375, 1.6822043718988375, 1.6822043718988375, 1.6822043718988375, 3.9504967739070556, 2.3583845724341095, 3.892594935288535, 5.774175809868039, 1.7590064444945004, 1.8465025223107228, 3.133531765531923, 6.013992634795805, 3.8939913548377985, 3.8519945794289208, 3.3013741685406623, 2.836389799784078, 2.5064104446132447, 2.0329176695471336, 1.7089872185590747, 2.2295199808815838, 2.1419212582076854, 1.598338575078593, 1.598338575078593, 1.598338575078593, 1.598338575078593, 1.598338575078593, 1.598338575078593, 1.598338575078593, 1.9695097106496444, 2.2853669766352245, 1.4728421183075842, 1.4693818908736516, 1.5825303503166575, 1.5825303503166575, 1.5825303503166575, 1.5825303503166575, 1.5825303503166575, 1.5825303503166575, 1.5825303503166575, 1.5825303503166575, 1.158865970747867, 2.2491906509172814, 2.2491906509172814, 3.386080606531623, 5.774175809868039, 3.5409283569860346, 6.013992634795805], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.2195, -3.5787, -3.6718, -3.8362, -3.9276, -3.9276, -3.9276, -3.9276, -3.9276, -3.9276, -3.9276, -3.9276, -3.9276, -3.7523, -4.2574, -4.7181, -4.7798, -4.7824, -4.9743, -4.9864, -4.9616, -5.0272, -5.0272, -5.0272, -5.0272, -5.0272, -5.0272, -5.0272, -5.0272, -5.0272, -4.565, -4.9869, -3.4291, -3.6708, -3.6849, -3.6849, -3.6849, -4.0437, -4.3742, -4.4094, -4.0114, -4.6569, -4.4696, -4.7846, -4.7846, -4.4094, -4.8258, -4.8297, -4.9014, -4.932, -4.9507, -4.9383, -5.0201, -5.0201, -5.0201, -5.0201, -5.0201, -5.0201, -5.0201, -5.0201, -5.0201, -5.0201, -4.2897, -4.7312, -4.3741, -4.2707, -4.9951, -4.983, -4.7845, -4.8922, -3.9397, -3.9525, -4.1279, -4.2905, -4.4397, -4.6747, -4.8879, -4.6244, -4.6688, -4.9736, -4.9736, -4.9736, -4.9736, -4.9736, -4.9736, -4.9736, -4.7728, -4.6262, -5.0964, -5.1088, -5.0489, -5.0489, -5.0489, -5.0489, -5.0489, -5.0489, -5.0489, -5.0489, -5.4144, -4.7513, -4.7513, -4.4373, -4.1336, -4.4861, -4.252], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.0043, 0.9899, 0.9842, 0.9674, 0.9602, 0.9602, 0.9602, 0.9602, 0.9602, 0.9602, 0.9602, 0.9602, 0.9602, 0.9426, 0.9152, 0.8373, 0.8186, 0.8138, 0.7803, 0.7784, 0.7724, 0.7692, 0.7692, 0.7692, 0.7692, 0.7692, 0.7692, 0.7692, 0.7692, 0.7692, -0.0205, 0.0873, 1.0113, 0.9948, 0.9938, 0.9938, 0.9938, 0.9441, 0.9201, 0.915, 0.9147, 0.8746, 0.8646, 0.8503, 0.8503, 0.8481, 0.8345, 0.8334, 0.8257, 0.8173, 0.8147, 0.8026, 0.7984, 0.7984, 0.7984, 0.7984, 0.7984, 0.7984, 0.7984, 0.7984, 0.7984, 0.7984, 0.6751, 0.7494, 0.6054, 0.3145, 0.7787, 0.7423, 0.4119, -0.3477, 1.0394, 1.0375, 1.0164, 1.0055, 0.98, 0.9544, 0.9148, 0.9124, 0.9081, 0.896, 0.896, 0.896, 0.896, 0.896, 0.896, 0.896, 0.888, 0.8858, 0.855, 0.8449, 0.8306, 0.8306, 0.8306, 0.8306, 0.8306, 0.8306, 0.8306, 0.8306, 0.7768, 0.7767, 0.7767, 0.6816, 0.4516, 0.5882, 0.2925]}, \"token.table\": {\"Topic\": [2, 3, 1, 3, 2, 2, 1, 1, 2, 3, 2, 3, 3, 3, 1, 1, 3, 1, 2, 2, 1, 2, 1, 3, 2, 3, 2, 1, 3, 2, 3, 3, 3, 1, 2, 1, 2, 1, 2, 3, 3, 3, 2, 2, 3, 1, 2, 3, 3, 1, 1, 2, 1, 3, 2, 2, 3, 1, 3, 2, 2, 2, 3, 2, 3, 3, 2, 3, 1, 2, 3, 3, 1, 3, 2, 1, 2, 1, 1, 2, 1, 2, 2, 3, 3, 2, 1, 1, 2, 1, 1, 2, 3, 2, 1, 3, 1, 3, 3, 2, 1, 2, 2, 1, 1, 1, 1, 2, 2, 2, 1, 3], \"Freq\": [0.5944580912432302, 0.6256496687198007, 0.9652718276642457, 0.6318994133666406, 0.9508130908314996, 0.5944580912432302, 0.9375403295651674, 0.33255777342133486, 0.16627888671066743, 0.4988366601320023, 0.892329689412856, 0.9087125078361289, 0.6318994133666406, 0.6318994133666406, 0.5814462243880486, 0.5814462243880486, 0.7051217008861939, 0.5814462243880486, 1.0149083444958222, 1.0177950521030292, 0.5814462243880486, 0.5944580912432302, 0.9541006669528541, 0.7979539042770838, 0.29532669661526584, 0.5906533932305317, 0.6784148577792338, 0.5814462243880486, 0.770417735076087, 0.9741448345760484, 0.6256496687198007, 0.6318994133666406, 0.6256496687198007, 0.8516630180569817, 0.5944580912432302, 0.9375403295651674, 0.989440116690492, 0.5576612623171556, 0.4446043733963471, 0.8892087467926942, 0.6318994133666406, 0.778817295336061, 0.5415643834315454, 0.5195546687153194, 0.5195546687153194, 0.5633983769487338, 0.5944580912432302, 0.5851418835321341, 0.9838076720763284, 0.5814462243880486, 0.9375403295651674, 0.5425720609595863, 0.28241181384736613, 0.5648236276947323, 0.9508130908314996, 0.9508130908314996, 0.6318994133666406, 0.9375403295651674, 0.8629125586927504, 0.5685027494526195, 0.7770624121524413, 0.8990785042030047, 0.6318994133666406, 0.7038927787334143, 0.9337411412002876, 0.6256496687198007, 0.4446043733963471, 0.8892087467926942, 0.25689803758784263, 0.5137960751756853, 0.25689803758784263, 0.6789593993612035, 0.5814462243880486, 0.8751329744619947, 0.5547690901237007, 0.9375403295651674, 0.84803811192497, 0.966275598908167, 0.9375403295651674, 0.5944580912432302, 0.31912872593147246, 0.6382574518629449, 0.989440116690492, 0.6318994133666406, 0.8970540821119584, 0.5944580912432302, 0.5814462243880486, 0.9375403295651674, 0.7254113518880362, 0.5814462243880486, 0.8618186625158918, 0.5944580912432302, 0.6256496687198007, 0.5944580912432302, 0.5463116509949678, 0.6256496687198007, 0.9519835870700135, 1.0154811571557565, 0.6256496687198007, 0.7325135280005048, 0.9375403295651674, 0.563738520470769, 0.5944580912432302, 0.9375403295651674, 0.9348595568881846, 0.9139412337227695, 0.2531327215870617, 0.759398164761185, 0.9384295110819277, 0.5500754263961183, 0.9294432302116056, 0.6805582716181626], \"Term\": [\"absence\", \"attached\", \"book\", \"cait\", \"cast\", \"cell\", \"certain\", \"character\", \"character\", \"character\", \"cheesier\", \"conclusion\", \"confusing\", \"corpse\", \"dealt\", \"detail\", \"didnt\", \"different\", \"disappointed\", \"doesnt\", \"done\", \"dropping\", \"enough\", \"ethan\", \"even\", \"even\", \"every\", \"fascination\", \"feel\", \"felt\", \"find\", \"finding\", \"finish\", \"first\", \"fix\", \"flaw\", \"forced\", \"found\", \"fresh\", \"fresh\", \"garnet\", \"get\", \"good\", \"got\", \"got\", \"hard\", \"highlight\", \"honest\", \"however\", \"husband\", \"ignored\", \"im\", \"interesting\", \"interesting\", \"justice\", \"killer\", \"laid\", \"largely\", \"lee\", \"left\", \"like\", \"little\", \"lost\", \"made\", \"make\", \"merely\", \"mind\", \"mind\", \"much\", \"much\", \"much\", \"obsession\", \"ohlsson\", \"okay\", \"one\", \"overlooked\", \"page\", \"part\", \"pevels\", \"phone\", \"place\", \"place\", \"precociousness\", \"rather\", \"reading\", \"reference\", \"relationship\", \"revelation\", \"scene\", \"seems\", \"sequel\", \"simply\", \"skimmed\", \"someone\", \"something\", \"somewhat\", \"sort\", \"started\", \"stereotype\", \"story\", \"stronger\", \"sure\", \"technology\", \"thanks\", \"theyre\", \"though\", \"time\", \"time\", \"unfortunately\", \"wasnt\", \"writing\", \"xd\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [3, 1, 2]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el321751403249031809924596997456\", ldavis_el321751403249031809924596997456_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el321751403249031809924596997456\", ldavis_el321751403249031809924596997456_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el321751403249031809924596997456\", ldavis_el321751403249031809924596997456_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "2     -0.152806 -0.026859       1        1  34.259306\n",
       "0      0.115155 -0.066002       2        1  34.166041\n",
       "1      0.037651  0.092861       3        1  31.574653, topic_info=              Term      Freq     Total Category  logprob  loglift\n",
       "13            book  8.000000  8.000000  Default  30.0000  30.0000\n",
       "377         little  6.000000  6.000000  Default  29.0000  29.0000\n",
       "17           first  5.000000  5.000000  Default  28.0000  28.0000\n",
       "25   unfortunately  5.000000  5.000000  Default  27.0000  27.0000\n",
       "390         killer  5.000000  5.000000  Default  26.0000  26.0000\n",
       "..             ...       ...       ...      ...      ...      ...\n",
       "366           mind  1.544127  2.249191   Topic3  -4.7513   0.7767\n",
       "295           even  2.113840  3.386081   Topic3  -4.4373   0.6816\n",
       "316            got  2.863850  5.774176   Topic3  -4.1336   0.4516\n",
       "63     interesting  2.013203  3.540928   Topic3  -4.4861   0.5882\n",
       "122      character  2.544131  6.013993   Topic3  -4.2520   0.2925\n",
       "\n",
       "[135 rows x 6 columns], token_table=      Topic      Freq           Term\n",
       "term                                \n",
       "321       2  0.594458        absence\n",
       "299       3  0.625650       attached\n",
       "13        1  0.965272           book\n",
       "305       3  0.631899           cait\n",
       "388       2  0.950813           cast\n",
       "...     ...       ...            ...\n",
       "340       2  0.759398           time\n",
       "25        2  0.938430  unfortunately\n",
       "187       2  0.550075          wasnt\n",
       "375       1  0.929443        writing\n",
       "214       3  0.680558             xd\n",
       "\n",
       "[112 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[3, 1, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis = pyLDAvis.gensim_models.prepare(best_model, corpus, dictionary)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
